{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94169eb1-78d7-410f-bc5f-67aa272b5485",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Regenie Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657995d7-0d9a-4806-8c55-9218bd57106a",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This piepeline implement regenie interaction based on a self-made version of regenie. It was built on the raw source code that has already had the code for interaction test and option from [https://github.com/rgcgithub/regenie](https://github.com/rgcgithub/regenie) (2021-11-24)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc4cc5-d3b7-4780-b575-3da13dcd244c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The regenie program can be found in `/mnt/mfs/statgen/guangyou/containers/regenie.v.2.3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c51d3-db43-44e4-bf5c-dd83c1852b5d",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Method\n",
    "\n",
    "### The interaction model\n",
    "\n",
    "$$\n",
    "y = \\beta_{0}+\\beta_{1} snp_{1}+\\beta_{2} snp_{2}+\\beta_{12} snp_{1}snp_{2}+\\beta_{c} c+g+\\varepsilon\\ \\ g\\sim MNV(0,\\sigma^{2}_{a}K), \\varepsilon\\sim MNV(0,\\sigma^{2}_{e}I_{N})\n",
    "$$\n",
    "\n",
    "Where $K$ is the genetic-relatedness matrix $K=\\frac{G_{S}G_{S}^{T}}{M}$, $G_{S}$ is the standardized genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad66b4-d860-4610-a105-db0c54ed1f89",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The interaction between covariates and genotypes are also supported. Only one phenotype is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aa7cd-1cd6-45b7-9c2f-c6563e8a5b68",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09be861b-09fb-48c8-887d-368e38b5bd3d",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run Regenie_interaction.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  regenie_qc\n",
      "  regenie\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --sampleFile . (as path)\n",
      "                        Path to sample file\n",
      "  --bfile VAL (as path, required)\n",
      "                        Genotype files in plink binary this is used for\n",
      "                        computing the GRM\n",
      "  --genoFile  paths('.')\n",
      "\n",
      "                        Path to bgen or bed files\n",
      "  --phenoFile VAL (as path, required)\n",
      "                        Phenotype file for quantitative trait (BMI)\n",
      "  --phenoCol VAL VAL ... (as type, required)\n",
      "                        Phenotype to be analyzed (specify the column)\n",
      "  --covarFile . (as path)\n",
      "                        Covariate file path. Will use phenoFile if empty\n",
      "  --formatFile . (as path)\n",
      "                        Summary statisticss format file path used for unifying\n",
      "                        output column names. Will not unify names if empty\n",
      "  --covarCol  (as list)\n",
      "                        Qualitative covariates to be used in the analysis\n",
      "  --qCovarCol  (as list)\n",
      "                        Quantitative covariates to be used in the analysis\n",
      "  --regenieFile VAL (as path, required)\n",
      "                        Path to regenie v2.3\n",
      "  --numThreads 2 (as int)\n",
      "                        Specific number of threads to use\n",
      "  --bgenMinMAF 0.001 (as float)\n",
      "                        Minimum MAF to be used\n",
      "  --bgenMinINFO 0.8 (as float)\n",
      "                        Mimimum info score to be used\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run job_sizeper job\n",
      "  --mem 2G\n",
      "                        For cluster jobs, mem to run job_sizeper job\n",
      "  --container-lmm 'statisticalgenetics/lmm:2.4'\n",
      "                        The container with the lmm software. Can be either a\n",
      "                        dockerhub image or a singularity `sif` file. Default is\n",
      "                        set to using dockerhub image\n",
      "  --container-marp 'gaow/marp'\n",
      "\n",
      "Sections\n",
      "  regenie_qc:           Select the SNPs and samples to be used based on maf,\n",
      "                        geno, hwe and mind options\n",
      "    Workflow Options:\n",
      "      --maf-filter 0.0 (as float)\n",
      "      --geno-filter 0.0 (as float)\n",
      "      --hwe-filter 0.0 (as float)\n",
      "      --mind-filter 0.0 (as float)\n",
      "  regenie_1:            Run REGENIE step 1: fitting the null\n",
      "    Workflow Options:\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --lowmem-dir  cwd\n",
      "\n",
      "                        Path to temporarily store block predictions\n",
      "      --trait bt\n",
      "                        Specify that traits are binary with\n",
      "                        0=control,1=case,NA=missing (default is quantitative)\n",
      "  regenie_2:            Run REGENIE step 2: association analysis\n",
      "    Workflow Options:\n",
      "      --bsize 400 (as int)\n",
      "                        Size of the genotype blocks to be used\n",
      "      --minMAC VAL (as int, required)\n",
      "                        Mimimum allele count to be used\n",
      "      --trait bt\n",
      "      --trunk-workers 1 (as int)\n",
      "      --walltime 2h\n",
      "      --[no-]ref-first (default to False)\n",
      "                        in the case of bgen data from UKBB ref_first should be\n",
      "                        set to true\n"
     ]
    }
   ],
   "source": [
    "sos run Regenie_interaction.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0c06b-3289-40da-9b6c-14e3e466da92",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 2\n",
    "# For cluster jobs, number commands to run job_sizeper job\n",
    "parameter: job_size = 1\n",
    "# For cluster jobs, wall time\n",
    "parameter: walltime = '1h'\n",
    "# For cluster jobs, mem to run job_sizeper job\n",
    "parameter: mem = '2G'\n",
    "# The container with the lmm software. Can be either a dockerhub image or a singularity `sif` file.\n",
    "# Default is set to using dockerhub image\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:2.4'\n",
    "parameter: container_annovar = 'gaow/gatk4-annovar'\n",
    "parameter: container_marp = 'gaow/marp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86e6ea-1f60-427d-803a-db8ae3c7dc29",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select the SNPs and samples to be used based on maf, geno, hwe and mind options\n",
    "[regenie_qc]\n",
    "# Genotype files in plink binary this is used for computing the GRM\n",
    "parameter: bfile = path\n",
    "parameter: maf_filter = 0.0\n",
    "parameter: geno_filter = 0.0\n",
    "parameter: hwe_filter = 0.0\n",
    "parameter: mind_filter = 0.0\n",
    "input: bfile\n",
    "output: f'{cwd}/cache/{bfile:bn}.qc_pass.id', f'{cwd}/cache/{bfile:bn}.qc_pass.snplist' \n",
    "task: trunk_workers = 1, walltime = '10h', mem = '5G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout' \n",
    "    plink2 \\\n",
    "      --bfile ${bfile:n} --mac 1 \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --write-snplist --write-samples --no-id-header \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output[0]:n} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3969be-07aa-49ec-ac2e-c943cf8403bc",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract and prepare phenotype & covariate files\n",
    "[regenie_1]\n",
    "# Phenotype file for quantitative trait (BMI)\n",
    "parameter: phenoFile = path\n",
    "# Phenotype to be analyzed (specify the column)\n",
    "parameter: phenoCol = list\n",
    "# Covariate file path. Will use phenoFile if empty\n",
    "parameter: covarFile = path('.')\n",
    "# Qualitative covariates to be used in the analysis\n",
    "parameter: covarCol = []\n",
    "# Quantitative covariates to be used in the analysis\n",
    "parameter: qCovarCol = []\n",
    "# Path to bgen or bed files \n",
    "parameter: genoFile = list\n",
    "# Interacting enviroment covariates to be used in the analysis\n",
    "parameter: covariates = list\n",
    "if not covarFile.is_file():\n",
    "    covarFile = phenoFile\n",
    "cwd = path(f\"{cwd:a}\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dat = pd.read_csv(phenoFile, header=0, delim_whitespace=True, dtype=str)\n",
    "dat = dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "if len(phenoCol) > 0:    \n",
    "    dat.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", sep='\\t', index=False, columns = ['FID', 'IID'] + phenoCol)\n",
    "dat = pd.read_csv(covarFile, header=0, delim_whitespace=True, dtype=str)\n",
    "if len(covarCol) > 0 or len(qCovarCol) > 0:\n",
    "    dat = dat.dropna(subset=covarCol)\n",
    "    dat = dat.dropna(subset=qCovarCol)\n",
    "    dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "    dat1 = pd.DataFrame(dat, columns = ['FID','IID'] + covarCol)\n",
    "    #dat1 = dat1.astype(int)\n",
    "    dat2 = pd.DataFrame(dat, columns = ['IID'] + qCovarCol)\n",
    "    merged_left = pd.merge(left=dat1, right=dat2, how='left', left_on='IID', right_on='IID')\n",
    "    merged_left.to_csv(f\"{cwd}/{phenoFile:bn}.regenie_covar\", sep=' ', index=False)\n",
    "input: for_each = dict(cov=covariates)\n",
    "output: f\"{cwd}/{phenoFile:bn}.{cov}.regenie_covar\"\n",
    "task: trunk_workers = 1, trunk_size = 2, walltime = '2h', mem = '2G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "python: container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    dat = pd.read_csv(\"${covarFile}\", header=0, sep='\\t', dtype=str)\n",
    "    if len(${covarCol}) > 0 or len(${qCovarCol}) > 0:\n",
    "        dat = dat.dropna(subset=${covarCol})\n",
    "        dat = dat.dropna(subset=${qCovarCol})\n",
    "        dat = dat.dropna(subset=[\"${cov}\"])\n",
    "        dat.replace(to_replace =np.nan, value =\"NA\")\n",
    "        dat1 = pd.DataFrame(dat, columns = ['FID','IID'] + ${covarCol} + [\"${cov}\"])\n",
    "        #dat1 = dat1.astype(int)\n",
    "        dat2 = pd.DataFrame(dat, columns = ['IID'] + ${qCovarCol})\n",
    "        merged_left = pd.merge(left=dat1, right=dat2, how='left', left_on='IID', right_on='IID')\n",
    "        merged_left.to_csv(\"${_output}\", sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3874b-010c-4e79-be97-9ca994c09d1c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 1: fitting the null\n",
    "[regenie_2]\n",
    "# Path to sample file\n",
    "parameter: sampleFile = path('.')\n",
    "# Genotype files in plink binary this is used for computing the GRM\n",
    "parameter: bfile = path\n",
    "# Phenotype file for quantitative trait (BMI)\n",
    "parameter: phenoFile = path\n",
    "# Phenotype to be analyzed (specify the column)\n",
    "parameter: phenoCol = list\n",
    "# Summary statisticss format file path used for unifying output column names. Will not unify names if empty\n",
    "parameter: formatFile = path('.')\n",
    "# Qualitative covariates to be used in the analysis\n",
    "parameter: covarCol = []\n",
    "# Quantitative covariates to be used in the analysis\n",
    "parameter: qCovarCol = []\n",
    "# Path to bgen or bed files \n",
    "parameter: genoFile = list\n",
    "# Interacting enviroment covariates to be used in the analysis\n",
    "parameter: covariates = list\n",
    "# Path to regenie v2.3\n",
    "parameter: regenieFile = path\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Path to temporarily store block predictions\n",
    "parameter: lowmem_dir = cwd\n",
    "# Specify that traits are binary with 0=control,1=case,NA=missing (default is quantitative)\n",
    "parameter: trait = 'bt'\n",
    "depends: f'{cwd}/cache/{bfile:bn}.qc_pass.snplist', f'{cwd}/cache/{bfile:bn}.qc_pass.id'\n",
    "input: geno = bfile, pheno = f\"{cwd}/{phenoFile:bn}.regenie_phenotype\", covar = f\"{cwd}/{phenoFile:bn}.regenie_covar\", qc = output_from(\"regenie_qc\")\n",
    "output: f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + f'.regenie_pred.list'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '24h', mem = '50G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', volumes = [f\"{lowmem_dir:a}:{lowmem_dir:a}\"]\n",
    "    ${regenieFile} \\\n",
    "      --step 1 \\\n",
    "      --bed ${_input[\"geno\"]:n} \\\n",
    "      --phenoFile ${_input[\"pheno\"]} \\\n",
    "      --covarFile ${_input[\"covar\"]} \\\n",
    "      --keep ${_input[\"qc\"][0]} \\\n",
    "      --extract ${_input[\"qc\"][1]} \\\n",
    "      ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "      --bsize ${bsize} \\\n",
    "      --lowmem --lowmem-prefix ${lowmem_dir:a}/${_output:bn} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:nn}.regenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5949b0-3626-4f3a-8d1d-60d576f317c0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run REGENIE step 2: association analysis\n",
    "[regenie_3]\n",
    "# Path to sample file\n",
    "parameter: sampleFile = path('.')\n",
    "# Phenotype file for quantitative trait (BMI)\n",
    "parameter: phenoFile = path\n",
    "# Phenotype to be analyzed (specify the column)\n",
    "parameter: phenoCol = list\n",
    "# Qualitative covariates to be used in the analysis\n",
    "parameter: covarCol = []\n",
    "# Quantitative covariates to be used in the analysis\n",
    "parameter: qCovarCol = []\n",
    "# Path to bgen or bed files \n",
    "parameter: genoFile = list\n",
    "# Interacting enviroment covariates to be used in the analysis\n",
    "parameter: covariates = list\n",
    "# Path to regenie v2.3\n",
    "parameter: regenieFile = path\n",
    "# Size of the genotype blocks to be used \n",
    "parameter: bsize = 400\n",
    "# Minimum MAF to be used\n",
    "parameter: bgenMinMAF = 0.001\n",
    "# Mimimum info score to be used\n",
    "parameter: bgenMinINFO = 0.8\n",
    "# Mimimum allele count to be used\n",
    "parameter: minMAC = int\n",
    "parameter: trait = 'bt'\n",
    "# in the case of bgen data from UKBB ref_first should be set to true\n",
    "parameter: ref_first= False\n",
    "input:for_each = [dict(geno = genoFile),dict(cov=covariates)]\n",
    "input_options = f\"--bgen {geno} --sample {sampleFile}\" if geno.endswith('.bgen') else f\"--bed \" + geno.split('.bed')[0]\n",
    "info = f'{cwd}/{phenoFile:bn}_' + \"_\".join([x for x in phenoCol]) + '.regenie_pred.list'\n",
    "outputprefix=f'{cwd}/cache/'+geno.split('/')[-1].split('.bgen')[0]+f'.{cov}'\n",
    "output: f'{cwd}/cache/'+geno.split('/')[-1].split('.bgen')[0]+f'.{cov}_'+ \"_\".join([x for x in phenoCol]) + f\".regenie.gz\"\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '200h', mem = '10G', max_walltime = '200h', cores = 2, tags = f'{step_name}_{_output:bn}'\n",
    "bash:container=container_lmm, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    set -e\n",
    "    ${regenieFile} \\\n",
    "     --step 2 \\\n",
    "     ${input_options} \\\n",
    "     --phenoFile ${cwd}/${phenoFile:bn}.regenie_phenotype \\\n",
    "     --covarFile ${cwd}/${phenoFile:bn}.${cov}.regenie_covar \\\n",
    "     --phenoColList ${','.join(phenoCol)} \\\n",
    "     ${('--' + trait) if trait in ['bt'] else ''} \\\n",
    "     ${('--ref-first') if ref_first else ''} \\\n",
    "     --interaction ${cov} \\\n",
    "     --firth 0.01 --approx \\\n",
    "     --pred ${info} \\\n",
    "     --bsize ${bsize} \\\n",
    "     --minMAC ${minMAC} \\\n",
    "     --minINFO ${bgenMinINFO}\\\n",
    "     --threads ${numThreads} \\\n",
    "     --out ${outputprefix} && \\\n",
    "     gzip -f --best ${_output:n}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a291dc8-f1b6-4600-a66a-3c8c30729761",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Annotation for variants in the top interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc0a6b-27a2-4ad3-b27b-e39e2b951cc6",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge Regenie sumstats, extract the top interaction terms.\n",
    "[annovar_1]\n",
    "# Set p-value to filter for annotations\n",
    "parameter: p_filter = 0\n",
    "# Top k interaction terms for annotations \n",
    "parameter: k = 0\n",
    "# Path sumstats file\n",
    "parameter: sumstatsFile = list\n",
    "input: sumstatsFile\n",
    "output: f'{cwd}/sumstats.snp_annotate'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "python: container=container_lmm, expand='${ }', stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    result = pd.DataFrame(columns=['CHROM', 'GENPOS', 'ID', 'ALLELE0', 'ALLELE1', 'A1FREQ', 'INFO', 'N','TEST', 'BETA', 'SE', 'CHISQ', 'LOG10P', 'EXTRA'])\n",
    "    if ${TRUE if p_filter !=0 else FALSE}:\n",
    "        for file in ${sumstatsFile}:\n",
    "            tmp = pd.read_csv(\"file\",compression=\"gzip\",header=0,sep=\" \")\n",
    "            tmp = tmp[tmp[\"TEST\"].str.startswith(\"ADD-INT_SNPx\")]\n",
    "            tmp = tmp[tmp[\"LOG10P\"] >= math.log10(${p_filter})]\n",
    "            result = result.append(tmp,ignore_index=True)\n",
    "        result = result.sort_values(\"LOG10P\", axis=0, ascending=False)\n",
    "        result.to_csv(\"${_output}\",sep = \" \",index=False)\n",
    "    elif ${TRUE if k !=0 else FALSE}:\n",
    "        for file in ${sumstatsFile}:\n",
    "            tmp = pd.read_csv(file,compression=\"gzip\",header=0,sep=\" \")\n",
    "            tmp = tmp[tmp[\"TEST\"].str.startswith(\"ADD-INT_SNPx\")]\n",
    "            result = result.append(tmp,ignore_index=True)\n",
    "            result = result.sort_values(\"LOG10P\", axis=0, ascending=False).iloc[:${k},:]\n",
    "        result.to_csv(\"${_output}\",sep = \" \",index=False)\n",
    "    else :\n",
    "        print(\"Please enter either top k or p value threshold to filter the variants for annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37123b48-f0b4-4957-8d24-c68242a1f010",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Get chr, start, end, ref_allele, alt_allele format for ANNOVAR input\n",
    "[annovar_2]\n",
    "output: f'{_input:n}.avinput'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "python: container=container_lmm, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout' \n",
    "    import pandas as pd\n",
    "    top = pd.read_csv(\"${_input}\",sep = \" \",header=0)\n",
    "    top = top[['CHROM', 'GENPOS', 'ALLELE1', 'ALLELE0']]\n",
    "    top[\"end\"] = top[\"GENPOS\"] +  top[\"ALLELE0\"].str.len()\n",
    "    top = top.astype(\"string\")\n",
    "    top[\"varID\"] = top[\"CHROM\"].str.cat(others=[top.GENPOS, df.ALLELE1, df.ALLELE0], sep=':')\n",
    "    top = top[['CHROM', 'GENPOS', \"end\", 'ALLELE1', 'ALLELE0',\"varID\"]]\n",
    "    top.to_csv(\"${_output}\",index=False,header=False,sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74fd8b-4f6d-45cd-9711-df2eb19ace89",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Annotate variants file using ANNOVAR\n",
    "[annovar_3]\n",
    "# humandb path for ANNOVAR\n",
    "parameter: humandb = path\n",
    "# Path to x-ref file\n",
    "parameter: xref_path = path\n",
    "# Human genome build hg19 or hg38\n",
    "parameter: build = 'hg38'\n",
    "# Annovar protocol\n",
    "if build == 'hg19':\n",
    "    protocol = ['refGene', 'refGeneWithVer', 'knownGene', 'ensGene', 'phastConsElements46way', 'gwasCatalog', 'gnomad211_exome', 'avsnp150', 'dbnsfp42a', 'dbscsnv11', 'gene4denovo201907']\n",
    "    operation = ['g', 'g', 'g', 'g', 'r', 'r', 'f', 'f', 'f', 'f', 'f']\n",
    "    arg = ['\"-splicing 12 -exonicsplicing\"', '\"-splicing 30\"', '\"-splicing 12 -exonicsplicing\"', '\"-splicing 12\"', '', '', '', '', '', '', '']\n",
    "else:\n",
    "    protocol = ['refGene', 'refGeneWithVer', 'knownGene', 'ensGene', 'phastConsElements30way', 'encRegTfbsClustered', 'gwasCatalog', 'gnomad30_genome', 'gnomad211_exome', 'gme', 'kaviar_20150923', 'avsnp150', 'dbnsfp41a', 'dbscsnv11', 'clinvar_20200316', 'gene4denovo201907']\n",
    "    operation = ['g', 'g', 'g', 'gx', 'r', 'r', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']\n",
    "    arg = ['\"-splicing 12 -exonicsplicing\"', '\"-splicing 30\"', '\"-splicing 12 -exonicsplicing\"', '\"-splicing 12\"', '', '', '', '', '', '', '', '', '', '', '', '']\n",
    "    \n",
    "#add xreffile to option without -exonicsplicing\n",
    "#mart_export_2019_LOFtools3.txt #xreffile latest option -> Phenotype description,HGNC symbol,MIM morbid description,CGD_CONDITION,CGD_inh,CGD_man,CGD_comm,LOF_tools\n",
    "parameter: x_ref = path(f\"{xref_path}/mart_export_2021_LOFtools.txt\")\n",
    "output: anno_file = f'{cwd}/{_input:bn}.{build}_multianno.csv'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}', template = '{cmd}' if executable('annotate_variation.pl').target_exists() else annovar_module\n",
    "bash: container=container_annovar, volumes=[f'{humandb:a}:{humandb:a}', f'{x_ref:ad}:{x_ref:ad}'], expand=\"${ }\", stderr=f'{_output:n}.err', stdout=f'{_output:n}.out'\n",
    "    #do not add -intronhgvs as option -> writes cDNA variants as HGVS but creates issues (+2 splice site reported only)\n",
    "    #-nastring . can only be . for VCF files\n",
    "    #regsnpintron might cause shifted lines (be carefull using)\n",
    "    table_annovar.pl \\\n",
    "        ${_input} \\\n",
    "        ${humandb} \\\n",
    "        -buildver ${build} \\\n",
    "        -out ${_output:nn}\\\n",
    "        -otherinfo\\\n",
    "        -remove \\\n",
    "        -polish \\\n",
    "        -nastring . \\\n",
    "        -protocol ${\",\".join(protocol)}\\\n",
    "        -operation ${\",\".join(operation)} \\\n",
    "        -arg ${\",\".join(arg)} \\\n",
    "        -csvout \\\n",
    "        -xreffile ${x_ref} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d2d67-7166-4bf1-b916-dbbcbb2e9689",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Re-format the annovar csv to have the BETA, SE and P in the front and with headers\n",
    "[annovar_4]\n",
    "input: named_output('anno_file')\n",
    "output: f'{cwd}/{_input:bn}.formatted.csv'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout' \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import csv\n",
    "    df = pd.read_csv('${_input}', header=0)\n",
    "    df1 = df[[\"Otherinfo1\"]]\n",
    "    df1 = df1.astype(str)\n",
    "    df2 = df1[\"Otherinfo1\"].str.split(\" \", n = 4, expand = True)\n",
    "    df2.columns = [\"alternate_id\", \"BETA\", \"SE\", \"P\"]\n",
    "    df = df2.join(df)\n",
    "    df.to_csv('${_output}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b062593-70ec-4215-927b-83c424aff5ea",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Annotate snps to gene\n",
    "[snp_to_gene]\n",
    "# Column name for BP\n",
    "parameter: bp = 'POS'\n",
    "# Column name for p-value\n",
    "parameter: pval = 'P'\n",
    "# Column name for SNP\n",
    "parameter: snp = 'SNP'\n",
    "# Path sumstats file\n",
    "parameter: sumstatsFile = path\n",
    "# Genome assembly hg_37, hg_38\n",
    "parameter: hg = int\n",
    "input: sumstatsFile\n",
    "output: f'{_input:nn}.gene_ann'      \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand='${ }', stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    library('snpGeneSets')\n",
    "    library('dplyr')\n",
    "    # Import the sumstats file as dataframe\n",
    "    data <- read.table(gzfile('${_input}'), header=T)\n",
    "    head(data)\n",
    "    # Filter SNPs with p-val <5e-06\n",
    "    # Subset data to obtain only chr, pos and snp for gene mapping\n",
    "    sig.p <- data %>%\n",
    "      filter(P < 5e-8) %>%\n",
    "      mutate(chr = CHR,\n",
    "             pos = ${bp},\n",
    "             snp = as.character(${snp})) %>%\n",
    "      select(chr, pos, snp)\n",
    "    head(sig.p)\n",
    "    # Get the annotation of SNPs with different genome assemblies\n",
    "    snpMapAnn<- getSNPMap(sig.p$snp, GRCh=${hg})\n",
    "    # Mapping SNPs to genes (define gene boundary ‘up’ for the upstream region and ‘down’ for the downstream region with default value of 2,000 bp for both)\n",
    "    snpGeneMapAnn<- snp2Gene(snpMapAnn$rsid_map$snp)\n",
    "    cat(\"The unique number of genes is\",length(unique(snpGeneMapAnn$map$gene_id),\"\\n\"))\n",
    "    cat(\"The number of variants that could not be mapped to a gene is:\",length(snpGeneMapAnn$other),\"\\n\")\n",
    "    #Get the gene-name and gene-id for the mapped variants\n",
    "    gene_mapped <- getGeneMap(snpGeneMapAnn$map$gene_id)$gene_map\n",
    "    # Merge the datasets\n",
    "    snp_gene = merge(x = snpMapAnn37$rsid_map,y = snpGeneMapAnn$map[,c(\"snp\", \"gene_id\")],by=\"snp\", all.x=TRUE)\n",
    "    snp_gene_2 = merge(x = snp_gene,y = gene_mapped[,c(\"gene_id\", \"gene_name\")],by=\"gene_id\", all.x=TRUE)\n",
    "    names(snp_gene_2)[names(snp_gene_2) == 'snp'] <- 'SNP'\n",
    "    snp_gene_3 = merge(x = snp_gene_2,y = data[,c(\"A1\", \"A2\", \"N\", \"AF1\",\"P\",\"BETA\", \"SE\", \"INFO\",\"SNP\")],by=\"SNP\", all.x=TRUE)\n",
    "    # Get the final table with ordered pval\n",
    "    final_gene_set <- snp_gene_3 %>%\n",
    "     select(chr, ${snp}, pos, A1, A2, N, AF1, BETA, SE, ${pval}, INFO, gene_id, gene_name) %>%\n",
    "     arrange(P)\n",
    "    names(final_gene_set)[names(final_gene_set) == 'chr'] <- 'CHR'\n",
    "    names(final_gene_set)[names(final_gene_set) == 'pos'] <- 'POS'\n",
    "    # Write results to a table\n",
    "    write.table(final_gene_set, '${_output}', sep = \"\\t\", quote=FALSE, row.names=FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
