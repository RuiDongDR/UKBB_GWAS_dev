{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9fbaa9f-c68d-4553-b6a1-6e9d4b040316",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# LDstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2558e-4481-474d-8723-9d76ac952922",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Check tutorial [here](http://www.christianbenner.com/#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e07551-3a85-4085-9251-ea5c0d11f446",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Installation\n",
    "\n",
    "```\n",
    "pip3 install https://files.pythonhosted.org/packages/a8/fd/f98ab7dea176f42cb61b80450b795ef19b329e8eb715b87b0d13c2a0854d/ldstore-0.1.9.tar.gz \n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e493a-c99c-4a71-8894-b31658163f67",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Create master file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede3fb5-d54b-4ef9-9088-489933fb1bce",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The master file is a semicolon-separated text file and contains no space. It contains the following mandatory column names and one dataset per line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38f88a-4d5f-4b50-9535-4bf46ce1f31c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For the Z file modify this file to be rsid:chrom:pos:a1:a2. Formatting for chromosome should be 01,02,03...etc\n",
    "\n",
    "For the sample files remember to use only unrelated individuals from the 500K genotyped participants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff109cb-404f-49ae-87bd-8934fed65cfa",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "# Run LDstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8517236-02b7-4e6d-ae2b-951905b42bb5",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Working directory: change accordingly\n",
    "parameter: cwd = path\n",
    "# Path to bgen or plink files\n",
    "parameter: masterfile = ''\n",
    "parameter: mem = '80G'\n",
    "parameter: walltime = '36h'\n",
    "parameter: numThreads = 4\n",
    "parameter: job_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aceebb-3726-49ea-9378-f179cceb05a3",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Create the z file the long way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d894056-53db-4f03-b8b0-88c3663babce",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation of the z file: it has to be space delimited and not tab delimited\n",
    "import glob, os, sys\n",
    "import pandas as pd\n",
    "log_file= open('/mnt/vast/hpc/csg/UKBiobank/results/pleiotropy_AD_ARHI/111822_LDstore_files/regions_chr1_22/regions1_22.log', \"w\")\n",
    "regions=glob.glob('/mnt/vast/hpc/csg/UKBiobank/results/pleiotropy_AD_ARHI/111822_LDstore_files/regions_chr1_22/**/*.variants', recursive=True)\n",
    "mfi_files=glob.glob('/mnt/vast/hpc/csg/UKBiobank_Yale_transfer/ukb39554_imputeddataset/ukb_mfi_chr*[0-9]_v3.txt', recursive=True)\n",
    "for filename in regions:\n",
    "    print(filename)\n",
    "    basename=os.path.basename(filename)\n",
    "    sp = basename.split(\"_\")[0]\n",
    "    chrom= sp.lstrip(\"0\")\n",
    "    print(basename)\n",
    "    fullregion = pd.read_csv(filename,header=0,sep=\"\\t\", skiprows=1, skipfooter=1, names=['alternate_ids', 'rsid', 'chromosome', 'position', 'number_of_alleles', 'allele1', 'allele2'])\n",
    "    print('The number of variants in the region is:',fullregion.shape[0])\n",
    "    mfi_file = [file for file in mfi_files if \"chr\" + chrom + \"_\" in file][0]\n",
    "    chrom_file = pd.read_csv(mfi_file,header=None,sep=\"\\t\", names=[\"alternate_id\", \"rsid\", \"position\", \"allele1\", \"allele2\", \"maf\", \"minor_allele\", \"info_score\"])\n",
    "    print('The number of variants in',mfi_file,'is:',chrom_file.shape[0])\n",
    "    subset_region=chrom_file.join(fullregion.set_index(['alternate_ids', 'rsid', 'position', 'allele1', 'allele2']), on=['alternate_id', 'rsid', 'position', 'allele1', 'allele2'], how='right')\n",
    "    maf=0.0001\n",
    "    subset_maf=subset_region[subset_region['maf'] > maf]\n",
    "    print('The number of variants in the maf',maf,'filtered z_file is:',subset_maf.shape[0])\n",
    "    subset_maf[[\"rsid\",\"chromosome\", \"position\", \"allele1\", \"allele2\", \"alternate_id\"]].to_csv(filename + '_' + str(maf) + '.z', sep=' ', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ecafa-ee94-44d8-85ce-f4841b93723c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Automatic creation of the masterfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ebbc1-f391-4c55-adfb-8679f21f8440",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Creation of the masterfile\n",
    "[masterfile (Creation of the master file)]\n",
    "# Number of samples present in the bgen file\n",
    "parameter: number_of_samples=int\n",
    "# Parameter for samples to be included the name has to end in .incl\n",
    "parameter: incl_samples = path('.')\n",
    "from datetime import datetime\n",
    "date = datetime.now().strftime('%Y%m%d')\n",
    "output: f'{cwd}/{masterfile}{date}'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    z_files = glob.glob(${cwd:r}+'/*/*.z')\n",
    "    df = pd.DataFrame({'z':z_files})\n",
    "    bgen=glob.glob(${cwd:r}+'/*/*.bgen')\n",
    "    df1 = pd.DataFrame({'bgen':bgen})\n",
    "    bgi=glob.glob(${cwd:r}+'/*/*.bgen.bgi')\n",
    "    df2 = pd.DataFrame({'bgi':bgi})\n",
    "    df3=pd.concat([df,df1,df2], axis=1)\n",
    "    bcor=[i.replace('bgen','bcor') for i in bgen]\n",
    "    df4 = pd.DataFrame({'bcor':bcor})\n",
    "    ld=[i.replace('bgen','ld') for i in bgen]\n",
    "    df5 = pd.DataFrame({'ld':ld})\n",
    "    df_final=pd.concat([df3,df4,df5], axis=1)\n",
    "    \n",
    "    print(df_final)\n",
    "    #Add a constant number to every row in the sample column (the number of samples to analyze)\n",
    "    df_final['n_samples'] = df_final.apply(lambda x:${number_of_samples}, axis=1)\n",
    "    df_final['incl'] = df_final.apply(lambda x:${incl_samples:r}, axis=1)\n",
    "    df_final.to_csv(${cwd}+'/'+${masterfile}+'_'+${date}, sep=\";\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfface8-0cf6-421b-adaf-8d0657bb1e86",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Running LDStore for BCOR file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a624d-c46a-4225-83d6-f37c46fa5a70",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create bdose file\n",
    "[bdose]\n",
    "input: masterfile\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = mem, cores = numThreads, tags = f'{_input:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_input}.stderr', stdout = f'{_input}.stdout'   \n",
    "    ~/ldstore_v2.0_x86_64/./ldstore_v2.0_x86_64  \\\n",
    "    --in-files ${_input:n} \\\n",
    "    --write-bcor --write-bdose --bdose-version 1.1 \\\n",
    "    --n-threads ${numThreads} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfecad-c8c0-416e-88c3-7c3aba9fa6be",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Create bcor files\n",
    "[bcor]\n",
    "input: masterfile\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = mem, cores = numThreads, tags = f'{_input:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_input}.stderr', stdout = f'{_input}.stdout'   \n",
    "    ~/ldstore_v2.0_x86_64/./ldstore_v2.0_x86_64  \\\n",
    "    --in-files ${_input} \\\n",
    "    --write-bcor \\\n",
    "    --read-only-bgen \\\n",
    "    --n-threads ${numThreads} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e57c0-e2cf-4c73-aabc-9df7dd4a61f0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Calculate LD\n",
    "[ld_1]\n",
    "input: masterfile\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = mem, cores = numThreads, tags = f'{_input:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_input}.stderr', stdout = f'{_input}.stdout'   \n",
    "    ~/ldstore_v2.0_x86_64/./ldstore_v2.0_x86_64 \\\n",
    "    --in-files ${_input} \\\n",
    "    --bcor-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf1eff-400e-4d65-a7bb-0b868ff9ff08",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ld_2]\n",
    "import pandas as pd\n",
    "master_list = pd.read_csv(masterfile,\";\")\n",
    "input_list = master_list.iloc[:,[0,4]].values.tolist()\n",
    "input:input_list, group_by = 2\n",
    "output:  f'{cwd:a}/{_input[1]:b}.npz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = mem, cores = numThreads, tags = f'{_input[0]:bn}'\n",
    "python: expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    z_file=pd.read_csv(${_input[0]:r}, \" \", skiprows=1, header=None)[5].to_numpy()\n",
    "    np_ld = np.loadtxt(${_input[1]:r}, dtype = \"float16\")\n",
    "    np.savez_compressed(\"${_output}\", np_ld, z_file, allow_pickel = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "Python3",
     "python3",
     "Python3",
     "#FFD91A",
     {
      "name": "ipython",
      "version": 3
     }
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
