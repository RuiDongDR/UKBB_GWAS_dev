{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5de5a3-9ab1-45a8-8eaf-528dee1d607b",
   "metadata": {},
   "source": [
    "# Import pVCF Genomic Data with Hail\n",
    "\n",
    "This notebook shows how to import genomic data from pVCFs into a Hail MatrixTable and save it to an Apollo database (dnax://) on the DNAnexus platform. See documentation for guidance on launch specs for the JupyterLab with Spark Cluster app for different data sizes: https://documentation.dnanexus.com/science/using-hail-to-analyze-genomic-data\n",
    "\n",
    "Pre-conditions for running this notebook successfully:\n",
    "\n",
    "   * pVCF(s) are uploaded to the project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa4327-09bc-43ca-a7aa-d81fba131f1c",
   "metadata": {},
   "source": [
    " ## 1) Initiate Spark and Hail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe6415-5767-4547-8b98-d0f99d86c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will output a red-colored message- this is expected.\n",
    "# The 'Welcome to Hail' message in the output will indicate that Hail is ready to use in the notebook.\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import hail as hl\n",
    "\n",
    "builder = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .enableHiveSupport()\n",
    ")\n",
    "spark = builder.getOrCreate()\n",
    "hl.init(sc=spark.sparkContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69812a5-a860-45c7-b2d1-aaf8691fb702",
   "metadata": {},
   "source": [
    "## 2) Locate and import data into a Hail MatrixTable\n",
    "\n",
    "All data uploaded to the project before running the JupyterLab app is mounted (https://documentation.dnanexus.com/user/jupyter-notebooks?#accessing-data) and can be accessed in `/mnt/project/<path_to_data>`. The file URL follows the format: `file:///mnt/project/<path_to_data>`\n",
    "\n",
    "\n",
    "Hail's `import_vcf` is used to import vcf formatted data\n",
    "\n",
    "The first thing we do is import (import_vcf) and convert the VCF file into a Hail native file format. This is done by using the write method below. The resulting file is **much faster** to process because it is scalable and easily parallelizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67814c-bab6-4625-8519-28219124d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables used in import\n",
    "\n",
    "file_url = \"file:///mnt/project//Bulk/Exome sequences/Population level exome OQFE variants, pVCF format - final release/ukb23157_c22_b0_v1.vcf.gz\" # regex can be used if genomic data is in multiple pVCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8284-d366-46d5-8c3f-6d847377bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import genomic data into a MT supported formats are VCF, (B)GEN, PLINK, TSV,\n",
    "\n",
    "mt = hl.import_vcf(file_url, \n",
    "                   force_bgz=True, \n",
    "                   reference_genome=\"GRCh38\", \n",
    "                   array_elements_required=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64f3ec-204d-4d3c-a26f-b02aadfdd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View basic properties of MT\n",
    "\n",
    "print(f\"Num partitions: {mt.n_partitions()}\")\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77425ef5-45e9-48f4-8a28-9ab434805b7a",
   "metadata": {},
   "source": [
    "## 3) Basic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474efcd-2f92-401b-a332-c90597e87c4f",
   "metadata": {},
   "source": [
    "We highly recommend exploring your `matrixTable` if this is your first time using Hail using functions like `show`, `summarize`, or `count`. One of our personal interactive favourites is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ec641-a364-4c91-93c2-7619d6608680",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe(widget=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4386e2-1507-484a-b8ff-9a8a55a39b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the first 5 variants\n",
    "mt.rows().select().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df6103-88f4-4dd4-bb44-8214da751f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the first 5 samples\n",
    "mt.s.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d0561-5340-4944-8c9e-a2dff3135e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the locus\n",
    "mt.locus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46320e0a-efc7-49f7-8368-83dc9bc37220",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the genotyoes\n",
    "mt.GT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48cdba-76e8-44b6-a479-ad53241889f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the first genotype calls \n",
    "mt.entry.take(5)\n",
    "\n",
    "#mt.entry.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e55138-9eb6-4b2d-a985-0c26afb49ceb",
   "metadata": {},
   "source": [
    "`summarize` Prints (potentially) useful information about any field or object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7690d-d7b6-4041-9e07-85c8c2e6db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.DP.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e2910-7417-43bc-b8c6-3439eb22629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.AD.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf8f64-4686-4983-9a04-24fbe1ff2267",
   "metadata": {},
   "source": [
    "`MatrixTable.count` returns a tuple with the number of rows (variants) and number of columns (samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003c37c-09f3-4f11-8278-b3b2ef686797",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091984ef-5b57-4693-b42f-db9074aecfa5",
   "metadata": {},
   "source": [
    "## Annotate MatrixTable with sample and phenotypes annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2c8ea-bb8b-4512-ad33-d2a2363d4cdf",
   "metadata": {},
   "source": [
    "Column fields you would annote phenotypes, ancestry, sex, and covariates\n",
    "\n",
    "Row fields can be used to store information like gene membership and functional impact for use in QC or analysis\n",
    "\n",
    "\n",
    "\n",
    "In Hail, annotate methods refer to adding new fields.\n",
    "\n",
    "   * MatrixTable's `annotate_cols` adds new column (sample) fields.\n",
    "   * MatrixTable's `annotate_rows` adds new row (variant) fields.\n",
    "   * MatrixTable's `annotate_entries` adds new entry (genotype) fields.\n",
    "   * Table's `annotate` adds new row fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8886d-7b0c-4399-9f70-48ce97f984a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To import a table with phenotypes, sex, etc\n",
    "table = (hl.import_table('data/1kg_annotations.txt', impute=True)\n",
    "         .key_by('Sample'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb33f3-64c0-4cb7-b689-f4241e807dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see the structure of the table\n",
    "table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160ffea-0f36-4cab-aed5-dc62835e05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see the contents of the table\n",
    "table.show(width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae948b0-5f80-48f5-aad8-a2bef829e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join phenotype table with matrix table\n",
    "mt = mt.annotate_cols(pheno = table[mt.s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ed998-4dc9-40de-a204-a674115a8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.col.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d84fd3-a72e-4f4a-8732-3c47a35b1cb9",
   "metadata": {},
   "source": [
    "## 4) Gathering some statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9212e-c9a9-421f-84e8-7801c1428386",
   "metadata": {},
   "outputs": [],
   "source": [
    "## counter is used to count the occurrence of one element \n",
    "pprint(table.aggregate(hl.agg.counter(table.SuperPopulation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36cc10-1a6d-4f83-a6d2-8f35ecabf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats is for useful statistics or numeric collections \n",
    "pprint(table.aggregate(hl.agg.stats(table.CaffeineConsumption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071780e7-4a94-4944-b9de-58c689d4e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get the count only in our cohort of interest\n",
    "mt.aggregate_cols(hl.agg.counter(mt.pheno.SuperPopulation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714b852-382c-49d7-b984-29895d2b0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats only in our dataset\n",
    "pprint(mt.aggregate_cols(hl.agg.stats(mt.pheno.CaffeineConsumption)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b401b-6661-4222-9c73-45ffb0d61606",
   "metadata": {},
   "source": [
    "## 5) Get histograms for DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb315983-ef46-41cf-bb31-22dfc9be4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.histogram(mt.DP, range=(0,30), bins=30, title='DP Histogram', legend='DP')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b9714d-992e-435d-89ff-2e8ad2505d47",
   "metadata": {},
   "source": [
    "## 6) Quality control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0ba87-a37d-4667-8d1e-99ce2a468df2",
   "metadata": {},
   "source": [
    "### Count before splitting multi-allelics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be30d7-b72e-4743-8906-53f3123056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## count operations are computationally very expensive \n",
    "n = mt.count()\n",
    "\n",
    "pprint('n samples:')\n",
    "print(n[1])\n",
    "pprint('n variants:')\n",
    "print(n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a181fa5-58e7-43e8-8e5e-2be2d26f6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.summarize_variants(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec5cb1-f78c-43a4-bde8-95f4716ce523",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To split multi-allelics\n",
    "mt = hl.split_multi_hts(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78728495-9c66-45a7-ac14-fbcf70b3a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the new numbers after splitting\n",
    "hl.summarize_variants(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d290d30-5f90-4a8a-9a18-a435d286bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.col.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7dea9-fbc2-4c4b-b537-0773665e0205",
   "metadata": {},
   "source": [
    "### Sample QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0e505-7bd6-4b8c-90c1-5cbaebdb6bfb",
   "metadata": {},
   "source": [
    "Use `sample_qc` function of Hail. Hail has the function `hl.sample_qc` to compute a list of useful statistics about samples from sequencing data. This function adds a new column field, sample_qc, with the computed statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa82b05-ef25-45c2-9cbb-66df545c92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hail has the sample_qc function which produces some useful metrics and stores them in a column \n",
    "mt = hl.sample_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ba148-06c3-487f-bd23-0755869783f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.col.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a5122-457f-4eb4-ac9d-e7ab9d02ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the QC metrics as a good place to start. The call rate and outliers\n",
    "p = hl.plot.histogram(mt.sample_qc.call_rate, range=(.88,1), legend='Call Rate')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0656b-f2bf-4bec-b6de-828a279add39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot sample genotype quality and outliers\n",
    "p = hl.plot.histogram(mt.sample_qc.gq_stats.mean, range=(10,70), legend='Mean Sample GQ')\n",
    "show(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4a2f9-5748-45a9-bcaa-b0e7e32faf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation between DP and GQ\n",
    "p = hl.plot.scatter(x=mt.sample_qc.dp_stats.mean,\n",
    "                    y=mt.sample_qc.call_rate,\n",
    "                    xlabel='Mean DP',\n",
    "                    ylabel='Call Rate',\n",
    "                    hover_fields={'ID': mt.s},\n",
    "                    size=8)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f0679-1fea-47ef-a113-d98fbfa2ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fac0f-a367-4770-95ec-e4b99af0c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying a call rate filter of 97%\n",
    "mt = mt.filter_cols(mt.sample_qc.call_rate >= 0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b43165-faac-4c72-96cf-9ebbe487cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.scatter(x=mt.sample_qc.dp_stats.mean,\n",
    "                    y=mt.sample_qc.call_rate,\n",
    "                    xlabel='Mean DP',\n",
    "                    ylabel='Call Rate',\n",
    "                    hover_fields={'ID': mt.s},\n",
    "                    size=8)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99aba9-3478-4df4-9233-403798e3a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe(widget=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1269035-93fd-4815-acb6-1a8f57cec36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of variants removed\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2f2c7-c2c1-4e43-8eef-8595e23dabe7",
   "metadata": {},
   "source": [
    "#### Sex imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6c9e90-0a10-41c1-9767-6504439c623b",
   "metadata": {},
   "source": [
    "We suggest inferring for sex using the Hail function `impute_sex`. This function should be performed on common biallelic SNPs (AF > 0.05) with a high callrate (callrate > 0.97). \n",
    "Suggested thresholds for this function include the following. We would also recommend plotting the data to observe data is within reasonable limits of thresholds set: aaf_threshold: 0.05 female_threshold: 0.5 male_threshold: 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad52bd-ea3c-4d15-9902-5166aa78eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter for high quality calls for sex QC\n",
    "mt = mt.filter_rows((hl.len(mt.alleles) == 2) & hl.is_snp(mt.alleles[0], mt.alleles[1]) &\n",
    "                            (hl.agg.mean(mt.GT.n_alt_alleles()) / 2 > 0.001) &\n",
    "                            (hl.agg.fraction(hl.is_defined(mt.GT)) > 0.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2dadfe-aa4c-491e-97d3-78caaa7802ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f4c0f-0383-484d-8d4f-a5963524a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing sex with thresholds defined above and write it into a Hail table\n",
    "imputed_sex = hl.impute_sex(mt.GT,aaf_threshold=0.05, female_threshold=0.5, male_threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bd012-a1b0-45e0-9e91-de68c4256d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_sex.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d48fd4-0471-4d85-823a-da3e9d736b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annotate matrix table with imputed sex\n",
    "mt = mt.annotate_cols(impute_sex = imputed_sex[mt.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e305d725-6449-41a0-8f91-00a140412f35",
   "metadata": {},
   "source": [
    "#### Additional filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788195df-8fa2-4765-b561-b3417eff4717",
   "metadata": {},
   "source": [
    "Recommended filters removing samples that are\n",
    "* Mean coverage < 20.0 \n",
    "* Ambiguous sex \n",
    "* Aneuploids \n",
    "* Call rate < 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3c2f3-d869-44bf-a02f-c1f72d8a1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(aneuploid= ((mt.impute_sex.f_stat >= 0.5) ) | (hl.is_missing(mt.impute_sex.f_stat)) | \n",
    "                      ((mt.impute_sex.f_stat >= 0.4) & (mt.impute_sex.f_stat <= 0.6) ) ,\n",
    "        sex_aneuploidy=(mt.impute_sex.f_stat < 0.4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa404d2-84f4-4ea2-9ac0-1e4c83e2885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e93e22-b0fe-401b-a0d9-7329a33e4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_cols( (mt.sample_qc.call_rate >= 0.97) &\n",
    "                    (mt.sample_qc.dp_stats.mean > 20) & (hl.is_defined(mt.aneuploid))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80bbe01-2016-4741-990f-87788a8b1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d12a85-70d3-4e93-8228-9c61a40e4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering based on DP and QC\n",
    "mt = mt.filter_cols((mt.sample_qc.dp_stats.mean >= 4) & (mt.sample_qc.call_rate >= 0.97))\n",
    "print('After filter, %d/284 samples remain.' % mt.count_cols())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71cc2bd-8e98-4871-acac-08f6cb8d806c",
   "metadata": {},
   "source": [
    "#### Relatedness filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee2332-1c6c-4bfb-ace3-bbce59151f00",
   "metadata": {},
   "source": [
    "Samples can be filtered to remove one of each pair of related samples using Hail's maximal_independent_set (uses model free relatedness estimation via PC-Relate). We suggest filtering for samples with second-degree relatedness or higher, where one of each pair of samples with a kinship coefficient of > 0.088 can be removed.\n",
    "\n",
    "Run PC-relate and compute pairs of closely related individuals: Note that the filtered kinship coefficient is already listed as the recommended 0.088\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfadf5f-20dc-4878-b110-1f7441f7d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_eigenvalues, pca_scores, pca_loadings = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741874e7-594f-4b5c-ba2c-fc2d7d98d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedness_ht = hl.pc_relate(mt.GT, min_individual_maf=0.01, scores_expr=pca_scores[mt.col_key].scores,\n",
    "                                      block_size=4096, min_kinship=0.1, statistics='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3fb33d-0d96-4032-bd67-01df88199199",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = relatedness_ht.filter(relatedness_ht['kin'] > 0.088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fb47f-7343-4571-8655-c97c21cf8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_samples_to_remove = hl.maximal_independent_set(pairs.i, pairs.j, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcb84e-007d-46b5-bd1f-8cbe3ddb1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b784e0a-b8a6-4a37-9f15-0f42a920968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_cols(hl.is_defined(related_samples_to_remove[mt.col_key]), keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814febc-2187-4b25-8f56-653fac4a4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f037f-ff6e-434f-b256-047d4a2f4217",
   "metadata": {},
   "source": [
    "#### Population ancestry inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8bc40-9606-45be-aabf-1c1722ab94fa",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA) is a very general statistical method for reducing high dimensional data to a small number of dimensions which capture most of the variation in the data. Hail has the function pca for performing generic PCA.\n",
    "\n",
    "PCA typically works best on normalized data (e.g. mean centered). Hail provides the specialized function `hwe_normalized_pca` which first normalizes the genotypes according to the Hardy-Weinberg Equilibium model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d7614-3398-41be-9b79-56a8cec00859",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_eigenvalues, pca_scores, pca_loadings = hl.hwe_normalized_pca(mt.GT, compute_loadings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05898c4-3398-4f6b-a5d3-05421b492433",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_cols(pca = pca_scores[mt.s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131d63f-7cf5-449f-945a-a402bfb0f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = pca_scores.select(PC1=pca_scores.scores[0],\n",
    "                       PC2=pca_scores.scores[1],\n",
    "                       PC3=pca_scores.scores[2],\n",
    "                       PC4=pca_scores.scores[3])\n",
    "ht = ht.annotate(pheno = sa[ht.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7eb85-876a-43fd-85f5-6bca466e4297",
   "metadata": {},
   "source": [
    "\n",
    "Visualize!\n",
    "\n",
    "Let's plot several combinations of the first four principal components (PCs) against each other. This will help us visualize the population structure of the dataset, and allow us to try identify our samples with different population ancestry clusters. Note that since the plots generated by the hl.plot module use the bokeh plotting library internally, we can use bokeh functions like gridplot to arrange plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ba64d-1211-45ed-bfcf-fe4717cb75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = hl.plot.scatter(ht.PC1, ht.PC2, xlabel='PC1', ylabel='PC2', label=ht.pheno.super_population, size=6)\n",
    "p2 = hl.plot.scatter(ht.PC1, ht.PC3, xlabel='PC1', ylabel='PC3', label=ht.pheno.super_population, size=6)\n",
    "p3 = hl.plot.scatter(ht.PC2, ht.PC4, xlabel='PC2', ylabel='PC4', label=ht.pheno.super_population, size=6)\n",
    "\n",
    "\n",
    "show(bokeh.layouts.gridplot([[p1], [p2], [p3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fed89-a52b-4199-87d9-dbbe78a1bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Based on your visualization, you can then choose to cluster your samples based on ancestry inference using the following code structure suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14194d20-f943-4ba8-932f-5b4d0a7fb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "check(ht.annotate(\n",
    "    unmasked = hl.case()\n",
    "        .when((ht.PC2 > 0.2) & (ht.PC1 < 0), 'EAS')\n",
    "#         .when(..., 'AFR')\n",
    "#         .when(..., 'AMR')\n",
    "#         .when(..., 'EUR')\n",
    "#         .when(..., 'SAS')\n",
    "        .default(ht.pheno.super_population)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3dfb7c-8894-4702-83d0-9539adb136e4",
   "metadata": {},
   "source": [
    "#### Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694dafc-0636-4eea-a673-f461de8f2628",
   "metadata": {},
   "source": [
    "Utilizing the Hail sample_qc method, we suggest removing outliers that deviate from the median and median absolute deviation (MAD) (non-parametric equivalent for mean and standard deviation) for the following metrics. It is also important to note that these outlier detection metrics below would need to be stratified by population ancestry (and sequencing platform) determined from subsection 2.0.5:\n",
    "\n",
    "`n_snp:` Number of SNP alternate alleles\n",
    "\n",
    "`r_ti_tv:` Transition/transversion ratio\n",
    "\n",
    "`r_insertion_deletion:` Insertion/Deletion allele ratio\n",
    "\n",
    "`n_insertion:` Number of insertion alternate alleles\n",
    "\n",
    "`n_deletion:` Number of deletion alternate alleles\n",
    "\n",
    "`r_het_hom_var:` Heterozygous/homozygous call ratio\n",
    "\n",
    "Using medians and median absolute deviation (MAD), we can estimate removal of outliers.\n",
    "\n",
    "The following code blocks:\n",
    "\n",
    "    1. is an outline of what can be done for separately for each population ancestry and sequencing platform.\n",
    "\n",
    "    2. look at the n_snp metric and needs to be interrogated (and replaced in script below) for r_ti_tv, r_insertion_deletion, n_insertion, n_deletion, and r_het_hom_var.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d0ec6-e28f-4d4a-b0ba-5be12d4bdd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values = hl.agg.collect(mt.sample_qc.n_snp)\n",
    "metric_median = hl.median(metric_values)\n",
    "metric_mad = 1.4826 * hl.median(hl.abs(metric_values - metric_median))\n",
    "outlier_metric=hl.struct( median=metric_median,\n",
    "            mad=metric_mad,\n",
    "            upper=metric_median + 4 * metric_mad,\n",
    "            lower=metric_median - 4 * metric_mad)\n",
    "\n",
    "\n",
    "mt = mt.annotate_globals(metrics_stats=mt.aggregate_cols(outlier_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d35c0-ec99-42ce-ae1e-edd0618dee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.globals.metrics_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f88754f-9e11-4692-87aa-87c92c61b408",
   "metadata": {},
   "source": [
    "Apply filter for the selected metric. Remember that this step needs to be done for each\n",
    "\n",
    "    1. population\n",
    "\n",
    "    2. sequencing platform\n",
    "\n",
    "    3. each metric (n_snp, r_ti_tv, r_insertion_deletion, n_insertion, n_deletion, and r_het_hom_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cfcf82-9d03-4b3b-9765-4729a5de7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt=mt.filter_cols( (mt.sample_qc.n_snp <= mt.metrics_stats.upper) |\n",
    "            (mt.sample_qc.n_snp >=  mt.metrics_stats.lower) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39724df9-bd7c-4032-9511-65458e067e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05242ef-e01b-4ee8-9c59-9949f62b05c0",
   "metadata": {},
   "source": [
    "## Genotype QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f349e73-b4fd-41b8-b31d-bd1431b819f9",
   "metadata": {},
   "source": [
    "High quality genotypes can be filtered when applying the following thresholds. We would also recommend performing call rate filtering separately for cases and controls: differential missingness is a typical source of false positives:\n",
    "\n",
    "GQ >= 20\n",
    "\n",
    "DP >= 10\n",
    "\n",
    "AB >= 0.25 (for each allele in heterozygous calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610ccfe-21e9-4682-99f8-97b3ce859f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an allele balance annotation\n",
    "mt= mt.annotate_entries(AB = (mt.AD[1] / hl.sum(mt.AD) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c584e18-ff8e-496f-8853-cfe7b82cf812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set filter condition for AB\n",
    "filter_condition_ab = ((mt.GT.is_hom_ref() & (mt.AB <= 0.1)) |\n",
    "                        (mt.GT.is_het() & (mt.AB >= 0.25) & (mt.AB <= 0.75)) |\n",
    "                        (mt.GT.is_hom_var() & (mt.AB >= 0.9)))\n",
    "fraction_filtered = mt.aggregate_entries(hl.agg.fraction(~filter_condition_ab))\n",
    "print(f'Filtering {fraction_filtered * 100:.2f}% entries out of downstream analysis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa08823-92bd-424d-b6d9-3bf7b0ca770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_entries( (mt.GQ>=20) &\n",
    "                 (mt.DP >= 10) &\n",
    "                 ((mt.GT.is_hom_ref() & (mt.AB <= 0.1)) |\n",
    "                        (mt.GT.is_het() & (mt.AB >= 0.25) & (mt.AB <= 0.75)) |\n",
    "                        (mt.GT.is_hom_var() & (mt.AB >= 0.9)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b6a1d-5ddb-4caa-ae75-eb441ccb2294",
   "metadata": {},
   "source": [
    "## Variant QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12391e50-185f-490e-91e7-b8174af15d36",
   "metadata": {},
   "source": [
    "Upon completion of the Sample QC described in section 2.0, exomes should then be processed for Variant QC that is further elaborated in this section 3.0. We recommend applying a PASS filter using the Variant Quality Score Recalibration (VQSR) metric.\n",
    "\n",
    "Hail has the function `hl.variant_qc` to compute a list of useful statistics about variants from sequencing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91a1f5-2328-4329-b2d4-4aa77fe12a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the varian_qc option of Hail to provide statistics\n",
    "mt = hl.variant_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b6409-a37f-42b5-b789-f7e5e25566b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(hl.plot.cdf(mt.variant_qc.call_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac7a67e-1083-4fce-98d2-877ecd430c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe(widget=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691e7d4-4129-4483-8d2f-9fd3da43607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.row.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd627b-b316-40f7-9e7e-d6bc88bbe4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.annotate_rows(fail_VQSR = hl.len(mt.filters) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ea587-261e-4bd3-9029-969036e40082",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.filter_rows(mt.fail_VQSR).count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e5f23-24b6-4e5b-952c-19a792eafea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.filters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523573ec-2669-4833-9e32-5eb35d0975b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Annotate variants with flag indicating if they failed VQSR. In this toy example, there is no information on VQSR, so everything is removed. Be weary of your data!\n",
    "\n",
    "mt = mt.annotate_rows(fail_VQSR = hl.len(mt.filters) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed2e9a-d33a-44c0-ba3b-b9e3d6895931",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_VQSR = mt.filter_rows(mt.fail_VQSR).count_rows()\n",
    "print('n variants failing VQSR:')\n",
    "pprint(fail_VQSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f56122-ebd6-4824-ac12-7107a489080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.filter_rows(mt.fail_VQSR, keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a98c4-5a8f-4bc3-ae48-a7606ad063d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter invariant rows\n",
    "mt = mt.filter_rows((mt.qc.AF[0] > 0.0) & (mt.qc.AF[0] < 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4dcbae-6e43-4e2b-9b79-8b9fd51ce0e8",
   "metadata": {},
   "source": [
    "# 7) Store Hail MT in DNAnexus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35bdfc-cb7a-4bbf-b20e-149258f1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and MT names\n",
    "\n",
    "# Note: It is recommended to only use lowercase letters for the database name.\n",
    "# If uppercase lettering is used, the database name will be lowercased when creating the database.\n",
    "db_name = \"database_name\"\n",
    "mt_name = \"geno.mt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a5cc2-b113-4144-b078-425618786110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database in DNAX\n",
    "\n",
    "stmt = f\"CREATE DATABASE IF NOT EXISTS {db_name} LOCATION 'dnax://'\"\n",
    "print(stmt)\n",
    "spark.sql(stmt).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ae397-8a59-4595-b43f-b5e731d61c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store MT in DNAX\n",
    "\n",
    "import dxpy\n",
    "\n",
    "# Find database ID of newly created database using dxpy method\n",
    "db_uri = dxpy.find_one_data_object(name=f\"{db_name}\", classname=\"database\")['id']\n",
    "url = f\"dnax://{db_uri}/{mt_name}\" # Note: the dnax url must follow this format to properly save MT to DNAX\n",
    "\n",
    "# Before this step, the Hail MatrixTable is just an object in memory. To persist it and be able to access \n",
    "# it later, the notebook needs to write it into a persistent filesystem (in this case DNAX).\n",
    "# See https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.write for additional documentation.\n",
    "mt.write(url) # Note: output should describe size of MT (i.e. number of rows, columns, partitions) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
